# ğŸ¤– Fund Analytics Chatbot

A conversational AI chatbot that answers questions about fund portfolios, trades, and holdings using local LLMs (Ollama) and function calling. No cloud dependencies, no API costs.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Setup & Configuration](#setup--configuration)
- [Usage](#usage)
- [Performance Optimizations](#performance-optimizations)
- [Troubleshooting](#troubleshooting)
- [Future Enhancements](#future-enhancements)

---

## ğŸ“Œ Overview

The Fund Analytics Chatbot is a **local-first, cost-free** solution for analyzing fund data via natural language. Instead of writing SQL or navigating spreadsheets, users ask questions in plain English:

- *"Show me top 5 holdings"*
- *"How many trades for fund XYZ?"*
- *"Compare all funds by market value"*

The chatbot:
1. Understands the query intent using a local LLM (Mistral via Ollama)
2. Maps the query to an analytics function (function calling pattern)
3. Executes the function against CSV data (Pandas)
4. Formats results into clear, factual natural language
5. Maintains conversation context across multiple turns

**Key benefit:** All processing happens locally. No data leaves your machine. No subscription fees.

---

## âœ¨ Features

- âœ… **Local LLM** â€” Uses Ollama (free, offline-capable, Mistral model)
- âœ… **Function Calling** â€” Precise query routing via LLM reasoning
- âœ… **CSV Data** â€” Load trades and holdings from CSV files
- âœ… **Streamlit UI** â€” Chat interface with persistent session state
- âœ… **Conversation Memory** â€” Session state stores chat history and cached results
- âœ… **Anti-hallucination** â€” Structured data only; no invented details
- âœ… **Performance Optimized** â€” Categorical dtypes, precomputed lowercase, caching
- âœ… **Error Handling** â€” Graceful fallbacks for missing data or connection issues

---

## ğŸ›  Tech Stack

| Component | Technology |
|-----------|-----------|
| **Backend LLM** | Ollama + Mistral |
| **Data Processing** | Pandas + NumPy |
| **UI Framework** | Streamlit |
| **Language** | Python 3.8+ |
| **HTTP Client** | Requests |
| **Logging** | Python logging |

---

## ğŸ“ Project Structure

```
fund-chatbot/
â”œâ”€â”€ app.py                          # Streamlit UI entry point
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ trades.csv                  # Trade records
â”‚   â””â”€â”€ holdings.csv                # Portfolio holdings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analytics.py                # Pure data functions (7 analytics)
â”‚   â””â”€â”€ data_loader.py              # LLM orchestration, session state
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ (optional exploratory analysis)
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # This file
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- Ollama installed ([https://ollama.ai](https://ollama.ai))
- pip or conda

### Step 1: Clone / Setup Project

```bash
cd fund-chatbot
```

### Step 2: Install Python Dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install streamlit pandas numpy requests
```

### Step 3: Install & Start Ollama

Download Ollama from [https://ollama.ai](https://ollama.ai), then:

```bash
# Pull the Mistral model (first time only, ~5GB download)
ollama pull mistral

# Start Ollama server (runs on localhost:11434)
ollama serve
```

**Note:** Keep this terminal window open. Ollama listens on `http://localhost:11434/api/generate`.

---

## âš™ï¸ Setup & Configuration

### CSV Data Format

Ensure your CSV files have these columns (case-sensitive):

**trades.csv:**
- `PortfolioName` â€” Fund name
- (other trade fields)

**holdings.csv:**
- `PortfolioName` â€” Fund name
- `SecName` â€” Security name
- `SecurityTypeName` â€” Type (e.g., "Equity", "Bond")
- `Qty` â€” Quantity
- `MV_Base` â€” Market value
- `PL_YTD` â€” Year-to-date profit/loss

### Environment Variables (Optional)

None required. Ollama runs locally by default at `http://localhost:11434`.

To use a remote Ollama instance, edit `src/data_loader.py`:

```python
OLLAMA_URL = "http://your-remote-host:11434/api/generate"
```

---

## ğŸ’¬ Usage

### Start the Chatbot UI

```bash
# Terminal 1: Start Ollama (if not already running)
ollama serve

# Terminal 2: Start Streamlit app
streamlit run app.py
```

The app opens at **http://localhost:8501**.

### Example Queries

1. **"Show me the top 5 holdings"**
   - Calls `get_top_holdings(limit=5)`
   - Returns formatted table of largest positions

2. **"How many trades for CoYold 1?"**
   - Calls `get_total_trades(fund="CoYold 1")`
   - Returns count of trades for that fund

3. **"Compare all funds by market value"**
   - Calls `get_fund_comparison()`
   - Returns sorted table of total values per fund

4. **"What's the yearly performance?"**
   - Calls `get_yearly_fund_performance()`
   - Returns P&L aggregated by fund

5. **"What holdings do we have by type?"**
   - Calls `get_fund_stats_by_type()`
   - Returns breakdown: Equities, Bonds, etc.

### UI Features

- **Chat History** â€” All messages persist in session state
- **Clear Chat** â€” Button to reset conversation
- **Sidebar Info** â€” Available funds, metrics, cached data explorer
- **Quick Tips** â€” Suggested queries

---

## ğŸ§  How It Works

### Architecture Flow

```
User Query
    â†“
[Streamlit Input]
    â†“
[LLM Prompt with Function Descriptions]
    â†“
[Ollama Generates Function Call Directive]
    â†“
[Parse & Execute Analytics Function]
    â†“
[Validate Result (not empty?)]
    â†“
[LLM Formats Structured Data â†’ Natural Language]
    â†“
[Append to Session State & Display]
```



## ğŸ“ Requirements

Create `requirements.txt`:

```
streamlit==1.28.0
pandas==2.0.0
numpy==1.24.0
requests==2.31.0
```

Install:

```bash
pip install -r requirements.txt
```

---

## ğŸ”’ Security & Limitations

- **Local only:** No data uploaded to cloud
- **No authentication:** Run on trusted networks only
- **CSV immutable:** Updates require restarting app
- **LLM limitations:** Mistral may occasionally misinterpret complex queries
- **No write operations:** Chatbot is read-only (reports, no updates)

---

## ğŸš€ Future Enhancements

1. **Database backend** â€” SQLite with indexes for large datasets
2. **Richer visualizations** â€” Inline charts (Plotly, Matplotlib)
3. **Export results** â€” PDF/CSV report generation
4. **Multi-model support** â€” Switch between Mistral, LLaMA, Neural-Chat
5. **API endpoint** â€” FastAPI wrapper for programmatic access
6. **Role-based access** â€” Restrict queries per user
7. **Audit logging** â€” Track all queries and responses
8. **Batch processing** â€” Queue multiple queries

---

## ğŸ“š References

- [Ollama Documentation](https://ollama.ai)
- [Streamlit Docs](https://docs.streamlit.io)
- [Pandas Documentation](https://pandas.pydata.org)
- [Function Calling Pattern](https://platform.openai.com/docs/guides/function-calling)

---

## ğŸ“ License

This project is open source and provided as-is for educational and commercial use.

---

## ğŸ‘¤ Author

Built by Divya for fund portfolio analytics.

---

## â“ Support

For issues:
1. Check [Troubleshooting](#troubleshooting)
2. Verify CSV column names match `analytics.py`
3. Ensure Ollama is running and reachable
4. Check logs: `streamlit run app.py --logger.level=debug`

---

**Happy querying! ğŸš€**